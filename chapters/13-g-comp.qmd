# G-computation {#sec-g-comp}

{{< include 00-setup.qmd >}}

```{r}
#| echo: false
# TODO: remove when first edition complete
status("wip")
```

## The Parametric G-Formula

The parametric g-formula provides a direct approach to causal estimation through outcome modeling. Rather than reweighting observations to balance confounders, as we have done so far in this book, we model the outcome as a function of exposure and covariates, then use that model to predict what would happen under different exposure scenarios. By averaging these predictions across the population, we obtain estimates of causal effects.

We start with fitting a conditional outcome model. Importantly, this means we must correctly specify the functional form of the outcome model. If our model is misspecified, our causal estimates will be biased. The outcome model must contain all variables in the adjustment set identified from the causal diagram. Like weighting and matching-based methods, valid inference is predicated on the assumption that this adjustment set is sufficient to identify the causal effect of interest. Once this model is fit, it can be used to generate predictions under counterfactual scenarios in which the exposure is set to the levels of interest. The resulting predicted outcomes are then averaged to create estimates of the expected outcome under each hypothetical intervention. The approach is called 'parametric' because we assume a specific parametric model (e.g., linear or logistic regression) for the outcome.

This approach has several advantages: it naturally handles multiple exposure comparisons, accommodates complex relationships through flexible modeling, and can be more efficient when outcomes are easier to model than exposure assignment. In this chapter, we will begin with the single-time-point setting, demonstrating the core logic of the g-formula with binary and continuous exposures. We then show how the same structure naturally expands to longitudinal settings with time-varying treatments and confounders.

### A Single-Time-Point Example

Let's again consider whether Extra Magic Morning hours influence the average posted wait time for the Seven Dwarfs Mine Train ride between 9 and 10am as described in @sec-data and assume the same data generating mechanism proposed in @fig-dag-magic-hours-wait. To implement the parametric g-formula we will (1) fit an outcome model with the exposure and all confounders, (2) create two versions of the dataset in which each observation is set to be exposed or unexposed, (3) generate predicted outcomes for each version using the fitted model, (4) average those predictions to construct marginal means by exposure, and (5) take the difference in marginal means to estimate the average treatment effect.

Let's first fit the outcome model that includes the exposure (`park_extra_magic_morning`) and all confounders (the historic high temperature on the day `park_temperature_high`, the time the park closed `park_close`, and the ticket season `park_ticket_season`).

```{r}
#| message: false
#| warning: false
library(tidyverse)
library(broom)
library(touringplans)

seven_dwarfs_9 <- seven_dwarfs_train_2018 |> 
  filter(wait_hour == 9)

gcomp_model <- lm(
  wait_minutes_posted_avg ~ 
    park_extra_magic_morning +
    park_ticket_season + 
    park_close + 
    park_temperature_high,
  data = seven_dwarfs_9
)
```

We then duplicate the `seven_dwarfs_9` dataset for each unique level of exposure (in this case two: one for the exposed and one for the unexposed). One copy assigns every park date as if Extra Magic Morning hours occurred and the other assigns every park date as if it did not. These counterfactual datasets represent the hypothetical worlds under which the exposure is uniformly set to each value. 

```{r}
exposed <- seven_dwarfs_9 |> mutate(park_extra_magic_morning = 1)
unexposed <- seven_dwarfs_9 |> mutate(park_extra_magic_morning = 0)
```

Using the perviously fitted outcome model, predicted outcomes are generated for each of these counterfactual datasets and averaged. These averages (marginal means) represent the expected posted wait time if everyone were exposed or if no one were exposed. We can then take the difference between these marginal means to estimate the causal effect of Extra Magic Morning on posted wait times.

```{r}
pred_exposed <- gcomp_model |> 
  augment(newdata = exposed) |> 
  select(pred_exposed = .fitted)

pred_unexposed <- gcomp_model |> 
  augment(newdata = unexposed) |> 
  select(pred_unexposed = .fitted)

bind_cols(pred_exposed, pred_unexposed) |> 
  summarize(
    mean_exposed = mean(pred_exposed),
    mean_unexposed = mean(pred_unexposed),
    difference = mean_exposed - mean_unexposed
  )
```
### Continuous Exposures

The same strategy applies when the exposure is continuous. For instance, imagine estimating how the actual wait time at 9am would change if the posted wait time at 8am were set to 60 minutes rather than 30 minutes. The procedure outlined above is identical, except that the exposure is set to the chosen numerical values for the counterfactual datasets.

Let's start by arranging the data so that the actual wait time at 9am can be modeled using the posted wait time at 8am and the same confounders idenfied above.

```{r}
eight <- seven_dwarfs_train_2018 |>
  filter(wait_hour == 8) |>
  select(-wait_minutes_actual_avg)

nine <- seven_dwarfs_train_2018 |>
  filter(wait_hour == 9) |>
  select(park_date, wait_minutes_actual_avg)

wait_times <- eight |> 
  left_join(nine, by = "park_date") |> 
  drop_na(wait_minutes_actual_avg)
```

We fit the outcome model the same way as for the binary exposure, as the outcome in both cases is continuous. Note now since we have a continuous exposure we can flexibly fit this, for example by using a natural spline.

```{r}
fit_wait <- lm(
  wait_minutes_actual_avg ~ 
    splines::ns(wait_minutes_posted_avg, 3) +
    park_extra_magic_morning + 
    park_ticket_season + 
    park_close + 
    park_temperature_high,
  data = wait_times
)
```

To compare posted wait times of 60 and 30 minutes, two counterfactual datasets are constructed: 

```{r}
high <- wait_times |> mutate(wait_minutes_posted_avg = 60)
low  <- wait_times |> mutate(wait_minutes_posted_avg = 30)

```

We then obtain predicted outcomes for each counterfactual dataset and then average these and take the difference:

```{r}
pred_high <- fit_wait |> augment(newdata = high) |> select(pred_high = .fitted)
pred_low  <- fit_wait |> augment(newdata = low)  |> select(pred_low  = .fitted)

bind_cols(pred_high, pred_low) |> 
  summarize(
    mean_high = mean(pred_high),
    mean_low = mean(pred_low),
    difference = mean_high - mean_low
  )
```
The resulting difference estimates how much the actual wait time would change if posted wait time were set to these two specific values and all other variables remained as observed.

### Time-varying Settings

The parameteric g-formula can naturally extend to scenarios when the exposure, covariates, and outcomes change over time. It is implemented through the following sequence of steps:

1. The time-ordered structure of the variables is laid out by drawing the appropriate DAG, which makes explicit the ordering of baseline covariates, time-varying covariates, treatment, and outcome.

2. For each time point after baseline, a parametric model is specified for every variable whose value evolves over time. Each model expresses the variable at that moment as a function of the variables that precede it in the graph. Linear models are commonly used for continuous variables and logistic regressions for binary variables, although any suitable parametric specification can be used.

3. Beginning with a sample from the observed distribution of baseline variables, the remaining variables are generated sequentially by sampling from the fitted models. This forward generation constitutes a Monte Carlo simulation of the data-generating process. When evaluating an intervention, the exposure is not simulated from its model; instead, it is set to follow the intervention regime under study at each time point.

4. Once the simulated outcomes have been produced under each intervention, the resulting distributions are compared to obtain the desired causal contrast.

Returning to the Seven Dwarfs Mine Train data, suppose the park is considering an operational policy that guarantees the posted wait at 8am never exceeds thirty minutes. The policy is expected to influence congestion later in the morning, since the early-morning posted wait affects how quickly queues accumulate. We therefore pose the following question:

> What would the average actual wait time at 10am have been if, for every park date, the posted wait at 8am were set to thirty minutes, compared with what was actually observed? 

Below is a proposed DAG to answer this causal question.

```{r}
#| label: fig-dag-morning-waits
#| code-fold: true
#| message: false
#| warning: false
#| fig.cap: >
#|   Time-ordered DAG representing the effect of setting the 8am posted wait
#|   to a fixed value on the actual wait at 10am. Baseline covariates influence
#|   each wait time; the posted wait at 8am influences the posted wait at 9am,
#|   and both influence the actual wait at 10am.

library(ggdag)
library(ggokabeito)

coord_dag <- list(
  x = c(Season = -1, close = -1, weather = -1,
        wait8 = 0, wait9 = 1, wait10 = 2),
  y = c(Season = 1, close = 0, weather = -1,
        wait8 = 0, wait9 = 0, wait10 = 0)
)

labels <- c(
  Season = "Ticket Season",
  weather = "Historic high temperature",
  close   = "Time park closed",
  wait8   = "8am posted wait",
  wait9   = "9am posted wait",
  wait10  = "10am actual wait"
)

dagify(
  wait8  ~ Season + weather + close,
  wait9  ~ wait8 + Season + weather + close,
  wait10 ~ wait9 + wait8 + Season + weather + close,
  coords = coord_dag,
  labels = labels,
  exposure = "wait8",
  outcome = "wait10"
) |>
  tidy_dagitty() |>
  node_status() |>
  ggplot(aes(x, y, xend = xend, yend = yend, color = status)) +
  geom_dag_edges_arc(curvature = c(rep(0, 6), .3)) +
  geom_dag_point() +
  geom_dag_label_repel(seed = 1630) +
  scale_color_okabe_ito(na.value = "grey90") +
  theme_dag() +
  theme(
    legend.position = "none",
    axis.text.x = element_text()
  ) +
  coord_cartesian(clip = "off") +
  scale_x_continuous(
    limits = c(-1.5, 2.5),
    breaks = c(-1, 0, 1, 2),
    labels = c(
      "Baseline\n(one year ago)",
      "8am\n(today)",
      "9am\n(today)",
      "10am\n(today)"
    )
  )

```

Because each park date includes hourly posted waits across the morning, these repeated measurements form a simple longitudinal sequence. Weather, ticket season, Extra Magic Morning, and closing time remain fixed for the date, but posted waits change from hour to hour and depend on what happened earlier. The posted wait at 8am influences the posted wait at 9am, and both influence the actual wait at 10am, so an intervention applied at 8am propagates forward through the subsequent hours.

To set up this example, let's reshape the 8am and 9am posted waits so that both appear on the same row, along with the baseline park-level features.

```{r}
df <- seven_dwarfs_train_2018 |>
  filter(wait_hour %in% c(8, 9)) |>
  select(
    park_date, wait_hour, wait_minutes_posted_avg,
    park_extra_magic_morning, park_ticket_season,
    park_close, park_temperature_high
  )

wide <- df |>
  pivot_wider(
    names_from = wait_hour,
    values_from = wait_minutes_posted_avg,
    names_prefix = "wait_"
  ) |>
  drop_na(wait_8, wait_9)
```

Now let's fit the model forthe posted wait, expressing its dependence on the 8am posted wait and the baseline covariates.

```{r}
m9 <- lm(
  wait_9 ~ wait_8 +
    park_extra_magic_morning +
    park_ticket_season +
    park_close +
    park_temperature_high,
  data = wide
)
```

To add the outcome, the 10am actual wait is merged with these data.

```{r}
ten <- seven_dwarfs_train_2018 |>
  filter(wait_hour == 10) |>
  select(park_date, wait_minutes_actual_avg)

three <- wide |>
  left_join(ten, by = "park_date") |>
  drop_na(wait_minutes_actual_avg)
```

Now let's fit a second model that describes the 10am actual wait in terms of the earlier posted waits and the same baseline confounders.

```{r}
m10 <- lm(
  wait_minutes_actual_avg ~
    wait_9 + wait_8 +
    park_extra_magic_morning +
    park_ticket_season +
    park_close +
    park_temperature_high,
  data = three
)
```

To evaluate an intervention, suppose that all park dates begin with an 8am posted wait of thirty minutes. The longitudinal g-formula uses the fitted models to reconstruct the rest of the morning under this counterfactual scenario. The observed data are first modified so that the 8am wait is replaced by the intervention value. The 9am posted wait is then generated from its model using this modified 8am value, and the 10am actual wait is generated from its model using both the modified 8am value and the model-based value of the 9am wait. This sequence reproduces the evolving process under the intervention.

```{r}
# Observed: use observed 8am waits
natural <- three |>
  mutate(
    wait_9_pred = predict(m9, newdata = cur_data()),
    wait_10_pred = predict(m10, 
      newdata = mutate(cur_data(), wait_9 = wait_9_pred))
  )

# Intervention: set all 8am waits to 30
intervention <- three |>
  mutate(wait_8 = 30) |>
  mutate(
    wait_9_pred = predict(m9, newdata = cur_data()),
    wait_10_pred = predict(m10, 
      newdata = mutate(cur_data(), wait_9 = wait_9_pred))
  )

# Estimate causal effect
tibble(
  natural_mean = mean(natural$wait_10_pred),
  intervention_mean = mean(intervention$wait_10_pred),
  ate = intervention_mean - natural_mean
)
```

The average of `wait_10` across all dates gives the estimated expected outcome under the intervention. Repeating the same procedure with the observed values of `wait_8` yields the expected outcome under the natural course. Their difference measures the effect of lowering the early-morning posted wait to thirty minutes.

For short sequences with deterministic models, the calculation can be performed exactly in this way. For longer sequences simulation becomes a natural computational tool. The simulation-based implementation is simply a practical method for evaluating the g-formula when the number of time points grows. Standard implementations create synthetic datasets of size 50-100 times the original sample by randomly sampling baseline covariates from the observed data. At each time point, confounders are simulated from fitted models using previously simulated values, exposure is assigned according to the intervention strategy, and outcomes are computed from fitted models. Let's set a seed for reproducibility (since we are introducing some random noise) and create a large synthetic population by sampling baseline covariates.

```{r}
set.seed(1)
n_mc <- nrow(three) * 50 # 50x the original sample size

baseline_sample <- three |>
  select(
    park_extra_magic_morning,
    park_ticket_season, 
    park_close,
    park_temperature_high,
    wait_8  
  ) |>
 slice_sample(n = n_mc, replace = TRUE)

```

Now let's simulate under the interventions, setting `wait_8` to 30 and running the values through the outcome models `m9` and `m10`.

```{r}
sim_intervention <- baseline_sample |>
  mutate(wait_8 = 30,
    # Simulate wait_9 using fitted model m9
    wait_9 = predict(m9, newdata = cur_data()),
    # Simulate wait_10 using fitted model m10
    wait_10 = predict(m10, newdata = cur_data())
  )
```

Next, let's simulate under the observed wait (leave `wait_8` as observed and run the values through the outcome models `m9` and `m10`).

```{r}
sim_natural <- baseline_sample |>
  # Keep observed wait_8 values
  mutate(
    wait_9 = predict(m9, newdata = cur_data()),
    wait_10 = predict(m10, newdata = cur_data())
  )
```

Finally, we can compare the average outcomes

```{r}
tibble(
  natural_course = mean(sim_natural$wait_10),
  intervention = mean(sim_intervention$wait_10),
  causal_effect = intervention - natural_course
)
```

This Monte Carlo approach propagates uncertainty forward through time, giving us not just a point estimate but a distribution of plausible outcomes under the intervention.


::: callout-tip
## Monte Carlo simulations

Monte Carlo simulations are computational approaches that generate a sample of outcomes for random processes.
One example would be to calculate the probability of rolling "snake eyes" (two ones) on a single roll of two six-sided dice.
We could certainly calculate this probability mathematically ($\frac{1}{6}*\frac{1}{6}=\frac{1}{36}\approx 2.8$%), though it can be just as quick to write a Monte Carlo simulation of the process (1,000,000 rolls shown below).

```{r}
n <- 1000000
tibble(
  roll_1 = sample(1:6, n, replace = TRUE),
  roll_2 = sample(1:6, n, replace = TRUE),
) |>
  reframe(roll_1 + roll_2 == 2) |>
  pull() |>
  sum() / n
```

Monte Carlo simulations are extremely useful for estimating outcomes of complex processes for which closed mathematical solutions are not easy to determine.
Indeed, that's why Monte Carlo simulations are so useful for the real-world causal mechanisms described in this book!
:::

