{
  "hash": "876c105eda910e33da19826666514f99",
  "result": {
    "markdown": "# G-computation {#sec-g-comp}\n\n\n\n\n\n## The Parametric G-Formula\n\nLet's pause to recap a typical goal of the causal analyses we've seen in this book so far: to estimate what would happen if *everyone* in the study were exposed versus what would happen if *no one* was exposed.\nTo do this, we've used weighting techniques that create confounder-balanced pseudopopulations which, in turn, give rise to unbiased causal effect estimates in marginal outcome models.\nOne alternative approach to weighting is called the parametric G-formula, which is generally executed through the following 4 steps:\n\n1. Draw the appropriate time ordered DAG (as described in @sec-dags).\n\n2. For each point in time after baseline, decide on a parametric model that predicts each variable's value based on previously measured variables in the DAG. \nThese are often linear models for continuous variables or logistic regressions for binary variables.\n\n3. Starting with a sample from the observed distribution of data at baseline, generate values for all subsequent variables according to the models in step 2 (i.e. conduct a *Monte Carlo simulation*). Do this with one key modification: for each exposure regime you are interested in comparing (e.g. everyone exposed versus everyone unexposed), assign the exposure variables accordingly (that is, don't let the simulation assign values for exposure variables).\n\n4. Compute the causal contrast of interest based on the simulated outcome in each exposure group.\n\n::: callout-tip\n## Monte Carlo simulations\n\nMonte Carlo simulations are computational approaches that generate a sample of outcomes for random processes.\nOne example would be to calculate the probability of rolling \"snake eyes\" (two ones) on a single roll of two six-sided dice. \nWe could certainly calculate this probability mathematically ($\\frac{1}{6}*\\frac{1}{6}=\\frac{1}{36}\\approx 2.8$%), though it can be just as quick to write a Monte Carlo simulation of the process (1,000,000 rolls shown below).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 1000000\ntibble(\n  roll_1 = sample(1:6, n, replace = TRUE),\n  roll_2 = sample(1:6, n, replace = TRUE),\n) |> \n  reframe(roll_1 + roll_2 == 2) |> \n  pull() |> \n  sum()/n\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.02787\n```\n\n\n:::\n:::\n\nMonte Carlo simulations are extremely useful for estimating outcomes of complex processes for which closed mathematical solutions are not easy to determine. \nIndeed, that's why Monte Carlo simulations are so useful for the real-world causal mechanisms described in this book!\n:::\n\n## Revisiting the magic morning hours example\n\nRecall in @sec-outcome-model that we estimated the impact of extra magic morning hours on the average posted wait time for the Seven Dwarfs ride between 9 and 10am.\nTo do so, we fit a propensity score model for the exposure (`park_extra_magic_morning`) with the confounders `park_ticket_season`, `park_close`, and `park_temperature_high`.\nIn turn, these propensity scores were converted to regression weights for the outcome model, which concluded that the expected impact of having extra magic hours on the average posted wait time between 9 and 10am is 6.2 minutes.\n\nWe will now reproduce this analysis, instead adopting the g-formula approach. Proceeding through the 4 steps outlined above, we begin by revisiting the time ordered DAG relevant to this question.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Proposed DAG for the relationship between Extra Magic Hours in the morning at a particular park and the average wait time between 9 am and 10 am. Here we are saying that we believe 1) Extra Magic Hours impacts average wait time and 2) both Extra Magic Hours and average wait time are determined by the time the park closes, historic high temperatures, and ticket season.](15-g-comp_files/figure-html/fig-dag-magic-hours-wait-take-2-1.png){#fig-dag-magic-hours-wait-take-2 width=672}\n:::\n:::\n\n\nThe second step is to specify a parametric model for each non-baseline variable that is based upon previously measured variables in the DAG. \nThis particular example is simple, since we only have two variables that are affected by previous features (`park_extra_magic_morning` and `wait_minutes_posted_avg`). \nLet's suppose that adequate models for these two variables are the simple logistic and linear models that follow.\nOf note, we're not yet going to use the model for the exposure (`park_extra_magic_morning`), but we're including the step here because it will be an important part of patterns you will see in the next section (@sec-dynamic).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages and data\nlibrary(broom)\nlibrary(touringplans)\n\nseven_dwarfs_9 <- seven_dwarfs_train_2018 |>\n  filter(wait_hour == 9)\n\n# A logistic regression for park_extra_magic_morning\nfit_extra_magic <- glm(\n  park_extra_magic_morning ~ \n    park_ticket_season + park_close + park_temperature_high,\n  data = seven_dwarfs_9,\n  family = \"binomial\"\n)\n\n# A linear model for wait_minutes_posted_avg\nfit_wait_minutes <- lm(\n  wait_minutes_posted_avg ~ \n    park_extra_magic_morning + park_ticket_season + park_close +\n    park_temperature_high,\n  data = seven_dwarfs_9\n)\n```\n:::\n\n\nNext, we need to draw a large sample from the distribution of baseline characteristics.\nDeciding how large this sample should be is typically based on computational availability; larger sample sizes can minimize the risk of precision loss via simulation error [@keil2014].\nIn the present case, we'll use sampling with replacement to generate a data frame of size 10,000.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# It's important to set seeds for reproducibility in Monte Carlo runs\nset.seed(8675309)\n\ndf_sim_baseline <- seven_dwarfs_9 |> \n  select(park_ticket_season, park_close, park_temperature_high) |> \n  sample_n(10000, replace = TRUE)\n```\n:::\n\n\nWith this population in hand, we can now simulate what would happen at each subsequent time point according to the parametric models we just defined. \nRemember that, in step 3, an important caveat is that for the variable upon which we wish to intervene (in this case, `park_extra_magic_morning`) we don't need to let the model determine the values; rather, we set them. \nSpecifically, we'll set the first 5000 to `park_extra_magic_morning = 1` and the second 5000 to `park_extra_magic_morning = 0`. \nOther simulations (in this case, the only remaining variable, `wait_minutes_posted_avg`) proceed as expected.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set the exposure groups for the causal contrast we wish to estimate\ndf_sim_time_1 <- df_sim_baseline |> \n  mutate(park_extra_magic_morning = c(rep(1, 5000), rep(0, 5000)))\n\n# Simulate the outcome according to the parametric model in step 2\ndf_outcome <- fit_wait_minutes |> \n  augment(newdata = df_sim_time_1) |> \n  rename(wait_minutes_posted_avg = .fitted)\n```\n:::\n\n\nAll that is left to do is compute the causal contrast we wish to estimate.\nHere, that contrast is the difference between expected wait minutes on extra magic mornings versus mornings without the extra magic program. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_outcome |> \n  group_by(park_extra_magic_morning) |> \n  summarize(wait_minutes = mean(wait_minutes_posted_avg))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  park_extra_magic_morning wait_minutes\n                     <dbl>        <dbl>\n1                        0         68.1\n2                        1         74.3\n```\n\n\n:::\n:::\n\n\nWe see that the difference, $74.3-68.1=6.2$ is the same as our estimate of 6.2 when we used IP weighting.\n\n## The g-formula for continuous exposures\n\nAs previously mentioned, a key strength of the g-formula is its capacity to handle continuous exposures, a situation in which IP weighting can give rise to unstable estimates. \nHere, we briefly repeat the example from @sec-continuous-exposures to show how this is done.\nTo extend the pattern, we will wrap this execution of the technique in a bootstrap to show how confidence intervals are computed.\n\nRecall, our causal question of interest is \"Do posted wait times for the Seven Dwarfs Mine Train at 8 am affect actual wait times at 9 am?\"\nThe time-ordered DAG for this question (step 1) is:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Proposed DAG for the relationship between posted wait in the morning at a particular park and the average wait time between 5 pm and 6 pm.](15-g-comp_files/figure-html/fig-dag-avg-wait-2-1.png){#fig-dag-avg-wait-2 width=672}\n:::\n:::\n\n\nFor step 2, we need to specify parametric models for the non-baseline variables in our DAG (i.e. any variables which have arrows into them).\nIn this case, we need such models for `park_extra_magic_morning`, `wait_minutes_posted_avg`, and `wait_minutes_actual_avg`; we'll assume that the below logistic and linear models are appropriate.\nOne extension to our previous implementation is that we're going to embed the each step of the process into a function, since this will allow us to bootstrap the entire pipeline and obtain confidence intervals.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(splines)\n\nfit_models <- function(.data) {\n  \n  # A logistic regression for park_extra_magic_morning\n  fit_extra_magic <- glm(\n    park_extra_magic_morning ~ \n      park_ticket_season + park_close + park_temperature_high,\n    data = .data,\n    family = \"binomial\"\n  )\n  \n  # A linear model for wait_minutes_posted_avg\n  fit_wait_minutes_posted <- lm(\n    wait_minutes_posted_avg ~ \n      park_extra_magic_morning + park_ticket_season + park_close +\n      park_temperature_high,\n    data = .data\n  )\n  \n  # A linear model for wait_minutes_actual_avg\n  # Let's go ahead an add a spline for further flexibility.\n  # Be aware this is an area where you can add many options here\n  # (interactions, etc) but you may get warnings and/or models which\n  # fail to converge if you don't have enough data.\n  fit_wait_minutes_actual <- lm(\n    wait_minutes_actual_avg ~ \n      ns(wait_minutes_posted_avg, df = 3) + \n      park_extra_magic_morning +\n      park_ticket_season + park_close +\n      park_temperature_high,\n    data = .data\n  )\n  \n  # return a list that we can pipe into our simulation step (up next)\n  return(\n    list(\n      .data = .data,\n      fit_extra_magic = fit_extra_magic,\n      fit_wait_minutes_posted = fit_wait_minutes_posted,\n      fit_wait_minutes_actual = fit_wait_minutes_actual\n    )\n  )\n  \n}\n```\n:::\n\n\nNext, we write a function which will complete step 3: from a random sample from the distribution of baseline variables, generate values for all subsequent variables (except the intervention variable) according to the models we defined. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# The arguments to simulate_process are as follows:\n# fit_obj is a list which is returned from our fit_models function\n# contrast gives exposure (default 60) and control group (default 30) settings\n# n_sample is the size of the baseline resample of .data\nsimulate_process <- function(\n    fit_obj, \n    contrast = c(60, 30),\n    n_sample = 10000\n) {\n  \n  # Draw a random sample of baseline variables\n  df_baseline <- fit_obj |> \n    pluck(\".data\") |> \n    select(park_ticket_season, park_close, park_temperature_high) |> \n    sample_n(n_sample, replace = TRUE)\n  \n  # Simulate park_extra_magic_morning\n  df_sim_time_1 <- fit_obj |> \n    pluck(\"fit_extra_magic\") |> \n    augment(newdata = df_baseline, type.predict = \"response\") |> \n    # .fitted is the probability that park_extra_magic_morning is 1,\n    # so let's use that to generate a 0/1 outcome\n    mutate(\n      park_extra_magic_morning = rbinom(n(), 1, .fitted)\n    )\n  \n  # Assign wait_minutes_posted_avg, since it's the intervention\n  df_sim_time_2 <- df_sim_time_1 |> \n    mutate(\n      wait_minutes_posted_avg = \n        c(rep(contrast[1], n_sample/2), rep(contrast[2], n_sample/2))\n    )\n  \n  # Simulate the outcome \n  df_outcome <- fit_obj |> \n    pluck(\"fit_wait_minutes_actual\") |> \n    augment(newdata = df_sim_time_2) |> \n    rename(wait_minutes_actual_avg = .fitted)\n  \n  # return a list that we can pipe into the contrast estimation step (up next)\n  return(\n    list(\n      df_outcome = df_outcome,\n      contrast = contrast\n    )\n  )\n}\n```\n:::\n\n\nFinally, in step 4, we compute the summary statistics and causal contrast of interest using our simulated data. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# sim_obj is a list created by our simulate_process() function\ncompute_stats <- function(sim_obj) {\n  \n  exposure_val <- sim_obj |> \n    pluck(\"contrast\", 1)\n  \n  control_val <- sim_obj |> \n    pluck(\"contrast\", 2)\n  \n  sim_obj |> \n    pluck(\"df_outcome\") |> \n    group_by(wait_minutes_posted_avg) |> \n    summarize(avg_wait_actual = mean(wait_minutes_actual_avg)) |> \n    pivot_wider(\n      names_from = wait_minutes_posted_avg, \n      values_from = avg_wait_actual,\n      names_prefix = \"x_\"\n    ) |> \n    summarize(\n      x_60, x_30, x_60 - x_30\n    )\n  \n}\n```\n:::\n\n\nNow, let's put it all together to get a single point estimate. \nOnce we've seen that in action, we'll bootstrap for a confidence interval.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Wrangle the data to reflect the causal question we are asking\neight <- seven_dwarfs_train_2018 |>\n  filter(wait_hour == 8) |>\n  select(-wait_minutes_actual_avg)\n\nnine <- seven_dwarfs_train_2018 |>\n  filter(wait_hour == 9) |>\n  select(park_date, wait_minutes_actual_avg)\n\nwait_times <- eight |>\n  left_join(nine, by = \"park_date\") |>\n  drop_na(wait_minutes_actual_avg)\n\n# get a single point estimate to make sure things work as we planned\nwait_times |> \n  fit_models() |> \n  simulate_process() |> \n  compute_stats() |> \n  # rsample wants results labelled this way\n  pivot_longer(\n    names_to = \"term\", \n    values_to = \"estimate\", \n    cols = everything()\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n  term        estimate\n  <chr>          <dbl>\n1 x_60            29.9\n2 x_30            40.6\n3 x_60 - x_30    -10.7\n```\n\n\n:::\n\n```{.r .cell-code}\n# compute bootstrap confidence intervals\nlibrary(rsample)\n\nboots <- bootstraps(wait_times, times = 1000, apparent = TRUE) |> \n  mutate(\n    models = map(\n      splits, \n      \\(.x) analysis(.x) |> \n        fit_models() |> \n        simulate_process() |> \n        compute_stats() |> \n        pivot_longer(\n          names_to = \"term\", \n          values_to = \"estimate\", \n          cols = everything()\n        )\n    )\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `models = map(...)`.\nCaused by warning:\n! glm.fit: fitted probabilities numerically 0 or 1 occurred\n```\n\n\n:::\n\n```{.r .cell-code}\nresults <- int_pctl(boots, models)\nresults\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 6\n  term        .lower .estimate .upper .alpha .method   \n  <chr>        <dbl>     <dbl>  <dbl>  <dbl> <chr>     \n1 x_30          33.1      40.6   48.8   0.05 percentile\n2 x_60          14.0      30.5   47.6   0.05 percentile\n3 x_60 - x_30  -30.8     -10.0   11.7   0.05 percentile\n```\n\n\n:::\n:::\n\n\nIn summary, our results are intepreted as follows: setting the posted wait time at 8am to 60 minutes results in an actual wait time at 9am of 31, while setting the posted wait time to 30 minutes gives a longer wait time of 41. Put another way, increasing the posted wait time at 8am from 30 minutes to 60 minutes results in a 10 minute shorter wait time at 9am.\n\nNote that one of our models threw a warning regarding perfect discrimination (`fitted probabilities numerically 0 or 1 occurred`); this can happen when we don't have a large sample size and one of our models is overspecified due to complexity.\nIn this exercise, the flexibility added by the spline in the regression for `wait_minutes_actual_avg` is what caused the issue.\nOne remedy when this happens is to simplify the offending model (i.e. if you modify the `wait_minutes_actual_avg` to include a simple linear term for `wait_minutes_posted_avg`), the warning is resolved.\nWe've left the warning here to highlight a common challenge that needs resolution when working with the parametric g-formula on small- to mid-sized data sets.\n\n## Dynamic treatment regimes with the g-formula {#sec-dynamic}\n\n\n## The Natural Course\n",
    "supporting": [
      "15-g-comp_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}